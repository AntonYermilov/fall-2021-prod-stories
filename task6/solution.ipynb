{"nbformat":4,"nbformat_minor":4,"metadata":{"language_info":{"file_extension":".py","version":"3.7.7","nbconvert_exporter":"python","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python","pygments_lexer":"ipython3"},"notebookId":"f21435e8-616e-490d-b16c-114c7926c603","kernelspec":{"name":"python3","description":"IPython kernel implementation for Yandex DataSphere","spec":{"language":"python","display_name":"Yandex DataSphere Kernel","codemirror_mode":"python","argv":["/bin/true"],"env":{},"help_links":[]},"resources":{},"display_name":"Yandex DataSphere Kernel"},"ydsNotebookPath":"prod-stories/task6/solution.ipynb"},"cells":[{"cell_type":"code","source":"%pip install jaro-winkler textdistance pyphonetics wordfreq cyhunspell","metadata":{"cellId":"hi2xj87i7bjqi6u4x2z2o","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"Defaulting to user installation because normal site-packages is not writeable\nCollecting jaro-winkler\n  Downloading jaro_winkler-2.0.0-py3-none-any.whl (33 kB)\nCollecting textdistance\n  Downloading textdistance-4.2.2-py3-none-any.whl (28 kB)\nCollecting pyphonetics\n  Downloading pyphonetics-0.5.3-py2.py3-none-any.whl (10 kB)\nCollecting wordfreq\n  Downloading wordfreq-2.5.1.tar.gz (56.8 MB)\n\u001B[K     |████████████████████████████████| 56.8 MB 29 kB/s  eta 0:00:01\n\u001B[?25hCollecting cyhunspell\n  Downloading cyhunspell-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (3.8 MB)\n\u001B[K     |████████████████████████████████| 3.8 MB 21.6 MB/s eta 0:00:01\n\u001B[?25hCollecting cacheman>=2.0.6\n  Downloading CacheMan-2.1.0-py2.py3-none-any.whl (12 kB)\nRequirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.7/dist-packages (from cacheman>=2.0.6->cyhunspell) (0.18.2)\nRequirement already satisfied: psutil>=2.1.0 in /kernel/lib/python3.7/site-packages (from cacheman>=2.0.6->cyhunspell) (5.7.3)\nRequirement already satisfied: six>=1.10.0 in /kernel/lib/python3.7/site-packages (from cacheman>=2.0.6->cyhunspell) (1.16.0)\nCollecting unidecode<2,>=1\n  Downloading Unidecode-1.3.2-py3-none-any.whl (235 kB)\n\u001B[K     |████████████████████████████████| 235 kB 54.9 MB/s \n\u001B[?25hCollecting msgpack>=1.0\n  Downloading msgpack-1.0.2-cp37-cp37m-manylinux1_x86_64.whl (273 kB)\n\u001B[K     |████████████████████████████████| 273 kB 89.1 MB/s \n\u001B[?25hCollecting langcodes>=3.0\n  Downloading langcodes-3.2.1.tar.gz (173 kB)\n\u001B[K     |████████████████████████████████| 173 kB 86.9 MB/s \n\u001B[?25hRequirement already satisfied: regex>=2020.04.04 in /usr/local/lib/python3.7/dist-packages (from wordfreq) (2021.7.6)\nCollecting ftfy>=3.0\n  Downloading ftfy-6.0.3.tar.gz (64 kB)\n\u001B[K     |████████████████████████████████| 64 kB 3.4 MB/s \n\u001B[?25hRequirement already satisfied: wcwidth in /kernel/lib/python3.7/site-packages (from ftfy>=3.0->wordfreq) (0.2.5)\nBuilding wheels for collected packages: wordfreq, ftfy, langcodes\n  Building wheel for wordfreq (setup.py) ... \u001B[?25ldone\n\u001B[?25h  Created wheel for wordfreq: filename=wordfreq-2.5.1-py3-none-any.whl size=56830992 sha256=e9914322b1fece78bc85cc4214f82a98a251efd38b7fc7c042c14d7fc66cfdb3\n  Stored in directory: /tmp/xdg_cache/pip/wheels/d8/d4/2d/741daa49d00231b4c5afbec15e79f361d9e76961f1a5fc02e5\n  Building wheel for ftfy (setup.py) ... \u001B[?25ldone\n\u001B[?25h  Created wheel for ftfy: filename=ftfy-6.0.3-py3-none-any.whl size=41913 sha256=a35a51dfdcbf6d25ab51927f29927ef6ca4291db1f0714d5684d104bb9d2724c\n  Stored in directory: /tmp/xdg_cache/pip/wheels/19/f5/38/273eb3b5e76dfd850619312f693716ac4518b498f5ffb6f56d\n  Building wheel for langcodes (setup.py) ... \u001B[?25ldone\n\u001B[?25h  Created wheel for langcodes: filename=langcodes-3.2.1-py3-none-any.whl size=169379 sha256=4756fc1ccf480f8ce18b4c0917c72c5e671b35565832c2368591f54d3c3953d7\n  Stored in directory: /tmp/xdg_cache/pip/wheels/12/9c/b3/d42c928e622075d3b6056733125190086e44c9230878e6eb2b\nSuccessfully built wordfreq ftfy langcodes\nInstalling collected packages: unidecode, msgpack, langcodes, ftfy, cacheman, wordfreq, textdistance, pyphonetics, jaro-winkler, cyhunspell\n\u001B[33m  WARNING: The script unidecode is installed in '/home/jupyter/.local/bin' which is not on PATH.\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001B[0m\n\u001B[33m  WARNING: The script ftfy is installed in '/home/jupyter/.local/bin' which is not on PATH.\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001B[0m\nSuccessfully installed cacheman-2.1.0 cyhunspell-2.0.2 ftfy-6.0.3 jaro-winkler-2.0.0 langcodes-3.2.1 msgpack-1.0.2 pyphonetics-0.5.3 textdistance-4.2.2 unidecode-1.3.2 wordfreq-2.5.1\n\u001B[33mWARNING: You are using pip version 21.0.1; however, version 21.3.1 is available.\nYou should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001B[0m\n"}],"execution_count":1},{"cell_type":"code","source":"import nltk\nnltk.download('punkt', quiet=True)","metadata":{"cellId":"1ujrstyx9zj5vm7pzt2e22","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"True"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"import numpy as np\nfrom nltk.tokenize import word_tokenize\nfrom hunspell import Hunspell\nfrom pyphonetics import RefinedSoundex\n\nfrom jaro import jaro_winkler_metric\nfrom textdistance import levenshtein\nfrom wordfreq import word_frequency","metadata":{"cellId":"w5jhiyu9pkp5oisxvmpw","trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def sort_candidates(word, candidates):\n    if len(candidates) == 0:\n            return []\n    \n    ","metadata":{"cellId":"vi8dux2zifpuu6loud635"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"hunspell = Hunspell('en_US')\nsoundex = RefinedSoundex()\n\n\ndef rank_suggestions(word, suggestions, n_suggestions):\n    features = np.zeros((len(suggestions), 4))\n    for i, suggestion in enumerate(suggestions):\n        text_edit_distance = levenshtein(word, suggestion)\n        phoneme_edit_distance = soundex.distance(word, suggestion, metric='levenshtein')\n        suggestion_prob = word_frequency(suggestion, 'en')\n        jw_distance = jaro_winkler_metric(word, suggestion)\n        \n        features[i] = np.array([text_edit_distance, phoneme_edit_distance, 1 - suggestion_prob, jw_distance])\n    \n    norm_features = ((features - features.min(axis=0)) / (features.max(axis=0) - features.min(axis=0) + 1e-9))\n    weights = norm_features.sum(axis=1)\n    ranked_suggestions = [suggestions[i] for i in np.argsort(weights)]\n    return ranked_suggestions[:n_suggestions]\n\n\ndef spellcheck(text: str, n_suggestions: int):\n    words = word_tokenize(text, 'english')\n    \n    for i, word in enumerate(words):\n        if not word.isalpha():\n            continue\n        if hunspell.spell(word):\n            continue\n        \n        suggestions = hunspell.suggest(word)\n        print(f'Word \"{word}\" at position {i} is probably misspelled.')\n        if not suggestions:\n            print(f'No fixes available.')\n        else:\n            print('Available fixes:')\n            for suggestion in rank_suggestions(word, suggestions, n_suggestions):\n                print(f'- {suggestion}')\n        print()","metadata":{"cellId":"b5isu66mpmu2mn19smgsij","trusted":true},"outputs":[{"output_type":"stream","name":"stderr","text":"/kernel/lib/python3.7/site-packages/ml_kernel/kernel.py:848: UserWarning: The following variables cannot be serialized: hunspell\n  warnings.warn(message)\n"}],"execution_count":8},{"cell_type":"code","source":"text = 'The Hamming distence is named after Richard Hamming, who intrdced the concept in his fundamental paper on Hamming codes, Error detecting and error corectin codes, in 1950. Hamming weight analysis of bits is used in several disciplines including infzzmation theory, coding theory, and cryptography.'\nn_suggestions = 4\nspellcheck(text, n_suggestions)","metadata":{"cellId":"5g5zgmzxz4hsm17iv197hd","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"Word \"distence\" at position 2 is probably misspelled.\nAvailable fixes:\n- distance\n- existence\n- insistence\n- distend\n\nWord \"intrdced\" at position 10 is probably misspelled.\nAvailable fixes:\n- introduced\n- intercede\n- interceded\n\nWord \"corectin\" at position 25 is probably misspelled.\nAvailable fixes:\n- correction\n- corrector\n- incorrect\n- corrective\n\nWord \"infzzmation\" at position 42 is probably misspelled.\nAvailable fixes:\n- information\n- inflammation\n- intimation\n\n"},{"output_type":"stream","name":"stderr","text":"/kernel/lib/python3.7/site-packages/ml_kernel/kernel.py:848: UserWarning: The following variables cannot be serialized: hunspell\n  warnings.warn(message)\n"}],"execution_count":12},{"cell_type":"code","source":"","metadata":{"cellId":"3quc910bsnn3kd0glgrrxp"},"outputs":[],"execution_count":null}]}